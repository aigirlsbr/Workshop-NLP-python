{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5_Y9OoBJGAb"
   },
   "source": [
    "# Introdução ao Processamento de Linguagem Natural usando Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhXZ9NhxJGAd"
   },
   "source": [
    "# Antes de começar!\n",
    "\n",
    "### Dicas!\n",
    "\n",
    "Para instalar novos pacotes:\n",
    "\n",
    " - pip install nome_do_pacote\n",
    "\n",
    "OU \n",
    "\n",
    " - conda install nome_do_pacote \n",
    "\n",
    "\n",
    "### Pacotes necessarios: \n",
    "    - conda install -c conda-forge wordcloud \n",
    "    - pip install nltk\n",
    "    - pip install pandas\n",
    "    - pip install spacy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bw8d2WMqJGAe"
   },
   "source": [
    "## Atenção!\n",
    "\n",
    "Os nomes das lojas foram ocultados para mantermos a segurança da loja.\n",
    "\n",
    "A empresa foi substituído por códigos para representar cada uma individualmente.\n",
    "\n",
    "Dentro do corpo da reclamação, o nome da loja foi substituído  por \"LOJA\"\n",
    "\n",
    "Nomes e emails também foram removidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2X-Y4I8JGAm"
   },
   "source": [
    "# Atenção!\n",
    "\n",
    "Antes de começarmos é necessario baixar a lista de stopwords, sentence tokenization e o corpus do NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1558171157864,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "GvP5M3-dJGAn",
    "outputId": "31051d70-90b3-41c2-8830-9d680e7a6ac3"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('machado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jPmiwmiJGAs"
   },
   "source": [
    "# 1. Exemplo -  Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1506,
     "status": "ok",
     "timestamp": 1558171158623,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "kSgOEdbnJGAs",
    "outputId": "4e291821-4239-47b0-8dba-27257ded5b8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import machado\n",
    "\n",
    "# Verificando o conjunto de textos contido no Corpus Machado\n",
    "print(machado.fileids())\n",
    "\n",
    "# Cada arquivo corresponde a uma das obras de Machado de Assis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1558171158625,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "OXb5EMf0JGAw",
    "outputId": "e6420133-419c-4ee2-f4dc-dd0fef05e3ce"
   },
   "outputs": [],
   "source": [
    "# Para acessar o texto como uma lista de 200 caracteres..\n",
    "raw_machado_text = machado.raw('romance/marm05.txt') # explore outros arquivos\n",
    "raw_machado_text[10000:10200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1471,
     "status": "ok",
     "timestamp": 1558171158626,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "fz2YjV70JGA0",
    "outputId": "67ea5a7c-c4ca-4226-cf84-b07f58d496fb"
   },
   "outputs": [],
   "source": [
    "# Porem, a forma acima não é uma maneira muito útil de trabalhar com um texto. \n",
    "# Geralmente pensamos em um texto como uma sequência de palavras e pontuação, não em caracteres..\n",
    "text1 = machado.words('romance/marm05.txt')\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1444,
     "status": "ok",
     "timestamp": 1558171158627,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "fPq8a5nrJGA4",
    "outputId": "773a6fee-30f0-4352-e524-0d6f0a49e0c4"
   },
   "outputs": [],
   "source": [
    "# Checando o tamanho do romance marm05.txt\n",
    "print('Quantidade de palavras {}'.format(len(text1)))\n",
    "# Checando o tamanho de palavras unicas do texto\n",
    "print('Quantidade de palavras unicas {}'.format(len(set(text1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-01nTl7JGA8"
   },
   "outputs": [],
   "source": [
    "# Sua vez: O que mais podemos fazer?\n",
    "# Liste aqui suas ideia!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsk56ZjhJGBA"
   },
   "source": [
    "http://www.nltk.org/howto/portuguese_en.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LdbVCis7JGBB"
   },
   "source": [
    "# Dados Reclame Aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaqY57CoJGBC"
   },
   "source": [
    "## 1. Importando os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para executar na sua maquina local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouGSFP_RJGBC"
   },
   "outputs": [],
   "source": [
    "# Descomente essa celula\n",
    "\n",
    "# # Importando Pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Vamos agora importar os dados que vamos trabalhar!\n",
    "# reclamacoes = pd.read_csv('reclamacoes.csv', sep=';')\n",
    "\n",
    "# print(reclamacoes.shape)\n",
    "\n",
    "# reclamacoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para executar no Google Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22252,
     "status": "ok",
     "timestamp": 1558196557330,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "3j9Q3t4GOCEb",
    "outputId": "57adab5f-01b9-445d-a852-ceb2567d9f21"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "data = io.BytesIO(uploaded['reclamacoes.csv'])    \n",
    "\n",
    "import pandas as pd   \n",
    "reclamacoes = pd.read_csv(data, sep=';')\n",
    "\n",
    "reclamacoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12469,
     "status": "ok",
     "timestamp": 1558171169719,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "WxEqugRiJGBG",
    "outputId": "23b872d5-599b-4977-8120-fb5f668eba14"
   },
   "outputs": [],
   "source": [
    "# Verificando se tem dados faltantes\n",
    "reclamacoes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uNo47yTJGBK"
   },
   "source": [
    "## 2.Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QA9quTiJGBL"
   },
   "source": [
    "### 2.1 Quebrando a coluna data_reclamacao em dia e hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1558197488280,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "hw7PVLLkJGBM",
    "outputId": "446e8b92-8f4b-40ee-ef68-57bc0fae789f"
   },
   "outputs": [],
   "source": [
    "# Vamos separar as informações\n",
    "\n",
    "print('Como era antes:')\n",
    "print(reclamacoes['data_reclamacao'][:3])\n",
    "\n",
    "# Separando...\n",
    "reclamacoes['data'] = reclamacoes['data_reclamacao'].str.split('às',expand=True)[0]\n",
    "# print(reclamacoes['data_reclamacao'].str.split('às',expand=True))\n",
    "print('\\n')\n",
    "print('Como ficou agora:')\n",
    "print(reclamacoes['data'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhs0_fehJGBP"
   },
   "outputs": [],
   "source": [
    "# Sua vez: Faça a mesma coisa para a informação hora\n",
    "\n",
    "# Você consegue identificar algo que está faltando ao utilizar essa nossa técnica?\n",
    "# Dica: Utilize reclamacoes.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6i8Z3XxJGBS"
   },
   "outputs": [],
   "source": [
    "# Como resolver o problema acima?\n",
    "# Sua solução:\n",
    "\n",
    "# Verifique se a sua solução funcionou:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYhPqshdJGBX"
   },
   "source": [
    "### 2.2 Quebrando a coluna local em Cidade e Estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCneDHAAJGBY"
   },
   "outputs": [],
   "source": [
    "# Sua vez: Faça a mesma coisa para que você fez acima para a variavel local e estado\n",
    "# não se esqueça do problema que resolvemos acima!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 581,
     "status": "error",
     "timestamp": 1558171213930,
     "user": {
      "displayName": "Juliana Neves",
      "photoUrl": "https://lh5.googleusercontent.com/-8tAstheGj8I/AAAAAAAAAAI/AAAAAAAAzyY/-HJ0sDR0-1E/s64/photo.jpg",
      "userId": "09752424162683127104"
     },
     "user_tz": 180
    },
    "id": "yCPxHaOhJGBc",
    "outputId": "7d02500e-a922-4a80-9111-7825dfaed62a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizando as alterações que fizemos\n",
    "reclamacoes[['data_reclamacao', 'data', 'hora', 'local', 'cidade', 'estado']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Igp33fr9JGBi"
   },
   "source": [
    "### 2.3 Alterar tipo de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSdyGIikJGBi",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verificando o tipo de dados \n",
    "reclamacoes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BmUP9gqJGBn"
   },
   "outputs": [],
   "source": [
    "# Colunas que são categoricas\n",
    "reclamacoes['teve_resposta'] = reclamacoes['teve_resposta'].astype('category')\n",
    "\n",
    "# Colunas que são datetime\n",
    "reclamacoes['data'] = pd.to_datetime(reclamacoes['data'])\n",
    "\n",
    "reclamacoes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRpnu_hiJGBq"
   },
   "source": [
    "### 2.4 LowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4vuqaw6JGBr"
   },
   "outputs": [],
   "source": [
    "print('Antes:')\n",
    "print(reclamacoes['corpo_reclamacao'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A950z2qmJGBu"
   },
   "outputs": [],
   "source": [
    "# Aplicando Lower Case\n",
    "reclamacoes['corpo_reclamacao_lower'] = [str(token).lower() for token in reclamacoes['corpo_reclamacao']]\n",
    "\n",
    "print('Depois:')\n",
    "reclamacoes.corpo_reclamacao_lower.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjqHfGVzJGB0"
   },
   "source": [
    "### 2.5 Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDRBSPAnJGB0"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Vamos dividir um exemplo texto em tokens/palavras:\n",
    "tokens = word_tokenize('A história do NLP começou na década de 1950, com Alan Turing'.lower())\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "print('\\nQuantidade de Tokens: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVA8rVC4JGB4"
   },
   "outputs": [],
   "source": [
    "# Agora vamos dividir um exemplo texto em sentenças:\n",
    "sentencas = sent_tokenize('O Processamento de Linguagem Natural (PLN) é a subárea da Inteligência Artificial (IA) que estuda a capacidade e as limitações de uma máquina em entender a linguagem dos seres humanos. O objetivo do PLN é fornecer aos computadores a capacidade de entender e compor textos. “Entender” um texto significa reconhecer o contexto, fazer análise sintática, semântica, léxica e morfológica, criar resumos, extrair informação, interpretar os sentidos, analisar sentimentos e até aprender conceitos com os textos processados.') \n",
    "\n",
    "# Visualizando cada sentença\n",
    "print(sentencas[0])\n",
    "print()\n",
    "print(sentencas[1])\n",
    "print()\n",
    "print(sentencas[2])\n",
    "\n",
    "print('\\nQuantidade de Sentenças: {}'.format(len(sentencas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aK4VXej6JGB7"
   },
   "outputs": [],
   "source": [
    "# Sua vez: Separe os nossos textos em tokens e coloque em uma nova coluna chamada corpo_reclamacao_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9f8hHctaJGB9"
   },
   "outputs": [],
   "source": [
    "# Como ficou nosso dataset até agora\n",
    "reclamacoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k56dbm_xJGCC"
   },
   "source": [
    "### 2.6 Remoção das StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k68gQgQEJGCD"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re # Regex\n",
    "\n",
    "#  Regex para encontrar pontuações dentro do texto\n",
    "other_punctuation_reg = r'(\\.{2,}|-+|—+|\\|+)'\n",
    "\n",
    "other_punctuation_finds = []\n",
    "\n",
    "# Percorre a lista de reclamções e identica as pontuações\n",
    "for text in reclamacoes.corpo_reclamacao_lower:\n",
    "    # encontra as pontuações\n",
    "    p = re.search(other_punctuation_reg, text)\n",
    "    if p:\n",
    "        other_punctuation_finds.append(p.group())\n",
    "\n",
    "# Gera lista com stopwords em Português  \n",
    "portuguese_stopswords = set(stopwords.words('portuguese') + list(punctuation) + other_punctuation_finds)\n",
    "\n",
    "# Adicionando outras palavras na nossa lista de StopWords\n",
    "portuguese_stopswords.add('é')\n",
    "\n",
    "portuguese_stopswords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K3nwqPssJGCH"
   },
   "source": [
    "O comando stopwords.words(\"portuguese\") lista todas as stopwords em português; \n",
    "\n",
    "OU\n",
    "\n",
    "Para visualizar a lista de StopWords:\n",
    "\n",
    "Windows:\n",
    "C:\\Users\\SEU_USUARIO\\AppData\\Roaming\\nltk_data\\corpora\\stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1X9jJ7CJGCI"
   },
   "outputs": [],
   "source": [
    "# Verificando como era antes\n",
    "print('Antes de remover as StopWords:')\n",
    "reclamacoes.corpo_reclamacao_lower[0] # visualizando somente a primeira reclamação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSg6N1PUJGCL"
   },
   "outputs": [],
   "source": [
    "# Exemplo - Removendo StopWords da primeira reclamação\n",
    "palavras_sem_stopwords = [token for token in reclamacoes['corpo_reclamacao_tokens'][0] if token not in portuguese_stopswords]\n",
    "palavras_sem_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xt-2RLLAJGCO"
   },
   "outputs": [],
   "source": [
    "# Função que remove as stopwords\n",
    "def remove_stopwords(text, portuguese_stopswords):\n",
    "    print('Tamanho do texto original {}'.format(len(word_tokenize(text))))\n",
    "    # Remove as stopwords\n",
    "    msgTokens_sem_stopwords = [token.lower() for token in word_tokenize(text) if token not in portuguese_stopswords]\n",
    "    print('Tamanho do texto sem stopwords {}'.format(len(msgTokens_sem_stopwords)))\n",
    "    print('Foram removidas {} stopwords'.format(len(word_tokenize(text))-len(msgTokens_sem_stopwords)))\n",
    "    aux_msgTokens = \" \".join(str(msg) for msg in msgTokens_sem_stopwords)\n",
    "    return aux_msgTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjvL7TVlJGCR"
   },
   "outputs": [],
   "source": [
    "# Removendo StopWords de todas as reclamações\n",
    "   \n",
    "# Percorre a lista de reclamações e cria uma coluna nova com o texto sem stopWords\n",
    "for idx,text in enumerate(reclamacoes.corpo_reclamacao_lower):\n",
    "    print('Removendo StopWords do index {}'.format(idx))\n",
    "    reclamacoes.at[idx, 'corpo_reclamacao_semStopWords'] = remove_stopwords(text, portuguese_stopswords)\n",
    "    print('---'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQW_yHYpJGCU"
   },
   "outputs": [],
   "source": [
    "# Removendo StopWords de todas as Tags\n",
    "\n",
    "# Percorre a lista de reclamações e cria uma coluna nova com o tags sem stop Words\n",
    "reclamacoes.tags = reclamacoes.tags.astype(str)\n",
    "for idx,text in enumerate(reclamacoes.tags):\n",
    "    print('Removendo StopWords do index {}'.format(idx))\n",
    "    reclamacoes.at[idx, 'Tags_semStopWords'] = remove_stopwords(text, portuguese_stopswords)\n",
    "    print('---'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ni5uEZ8KJGCY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reclamacoes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQaWbTVgJGCb"
   },
   "source": [
    "### 2.7 Normalização das palavras - Stemming e Lemmatization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ4wu4zjJGCc"
   },
   "source": [
    "Na língua portuguesa temos diferentes palavras flexionadas em gênero, número ou grau, além de alguns tempos verbais distintos.\n",
    "\n",
    "*Reclamar – Reclamação*\n",
    "\n",
    "*Problema – Problemão*\n",
    "\n",
    "A normalização de palavras pode ser entendida como a simplificação ou a radicalização de palavras.\n",
    "\n",
    "E existem duas técnicas mais conhecidas:\n",
    "\n",
    "*Stemming* - O processo de stemming consiste em reduzir a palavra à sua raiz, não levando em consideração a classe gramatical da palavra.\n",
    "\n",
    "*Lemmatization* - Consiste em aplicar técnicas para deflexionar as palavras (retira a conjugação verbal, caso seja um verbo, e altera os substantivos e os adjetivos para o singular masculino, de maneira a reduzir a palavra até sua forma de dicionário).\n",
    "\n",
    "Ex.:\n",
    "\n",
    "Menino: menino, menina, meninão\n",
    "\n",
    "Ficar: ficar, ficou, fique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6DlvRoHJGCd"
   },
   "outputs": [],
   "source": [
    "nltk.download('rslp')\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "palavras = ['reclamação', 'reclamei', 'reclamando']\n",
    "\n",
    "for w in palavras:\n",
    "    print(stemmer.stem(w))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hP_ps5o2JGCf"
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgLYgf5gJGCg"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gih71Pp3JGCl"
   },
   "source": [
    "Exemplo de lematização, porém não existe uma biblioteca em português apenas em inglês no momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgWwG4XjJGCm"
   },
   "outputs": [],
   "source": [
    "palavras = ['jumps', 'ladies', 'oranges']\n",
    "\n",
    "for w in palavras:\n",
    "    print(lemmatizer.lemmatize(w))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hf6XgWHGJGCr"
   },
   "source": [
    "## 3.Análise dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCDKBGk1JGCs"
   },
   "source": [
    "### 3.1 Analise Empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZgpY76ZIJGCu"
   },
   "outputs": [],
   "source": [
    "# Gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# Quantidade de reclamcoes por empresa\n",
    "empresa = reclamacoes.groupby(\"empresa\")\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "empresa.size().sort_values(ascending=False).plot.bar()\n",
    "plt.title(\"Quantidade de reclamacões por empresa\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel(\"Empresas\")\n",
    "plt.ylabel(\"Número de reclamações\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c044nWVQJGCx"
   },
   "source": [
    "### 3.2 Cidade e Estado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUBt85aAJGCy"
   },
   "source": [
    "#### Cidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4sXzJ36JGCy"
   },
   "outputs": [],
   "source": [
    "# Vendo quando locais recebem vem as reclamações\n",
    "cidades = reclamacoes.groupby(\"cidade\")\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "cidades.size().sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Cidades\")\n",
    "plt.ylabel(\"Numero de reclamações\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TxkujueaJGC3"
   },
   "source": [
    "#### Estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IyajdrSqJGC4"
   },
   "outputs": [],
   "source": [
    "# Vendo quando locais recebem vem as reclamações\n",
    "estados = reclamacoes.groupby(\"estado\")\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "estados.size().sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Estados\")\n",
    "plt.ylabel(\"Numero de reclamações\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4oJshLXJGC9"
   },
   "source": [
    "### 3.3 Frequencia de palavras de todas as reclamações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjtGLGKRJGC-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NLTK\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#função para ver as palavras mais frequente de todas as reclamações \n",
    "\n",
    "def freq_Words(text, number,titulo):\n",
    "    words = word_tokenize(text)\n",
    "    fdist = FreqDist(word for word in words)\n",
    "    XY = fdist.items()\n",
    "    XY = sorted(XY, key=lambda pair: pair[1], reverse=True)\n",
    "    limit = number\n",
    "    X = [x for (x,y) in XY[:limit]]\n",
    "    Y = [y for (x,y) in XY[:limit]]\n",
    "    nX = range(len(X))\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.title(\"Tokens mais frequentes das {}\".format(titulo))\n",
    "    plt.plot(nX, Y, label='contagens dos tokens', color = \"red\")\n",
    "    plt.xticks(nX, X, rotation='vertical')\n",
    "    plt.xticks(rotation='60')\n",
    "    plt.xlabel('Tokens')\n",
    "    plt.ylabel('Contagens')\n",
    "    plt.grid()\n",
    "    plt.legend(loc='upper right', fontsize='small')\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPXIXw9MJGDB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#juntando todas as mensagens em um unico texto\n",
    "lista_reclamacao = ' '.join(reclamacoes.corpo_reclamacao_semStopWords.tolist())\n",
    "frequencia = freq_Words(lista_reclamacao,10,\"reclamações\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fM-qQnkJJGDH"
   },
   "source": [
    "### 3.4 Frequencia de palavras de todas as tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPJbweLVJGDI"
   },
   "outputs": [],
   "source": [
    "lista_tags = ' '.join(reclamacoes.Tags_semStopWords.tolist())\n",
    "frequencia = freq_Words(lista_tags,10,\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAkaTN1vJGDL"
   },
   "source": [
    "### 3.5 Frequencia de Respostas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7wsbhLHJGDM"
   },
   "outputs": [],
   "source": [
    "reclamacoes.teve_resposta = reclamacoes.teve_resposta.replace(0,\"Não Respondido\")\n",
    "reclamacoes.teve_resposta = reclamacoes.teve_resposta.replace(1,\"Respondido\")      \n",
    "\n",
    "respostas = reclamacoes.groupby(\"teve_resposta\")\n",
    "plt.figure(figsize=(10,5))\n",
    "respostas.size().sort_values(ascending=False).plot.bar()\n",
    "plt.title(\"Quantas reclamações foram respondidas?\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel(\"Respostas\")\n",
    "plt.ylabel(\"Numero de respostas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyFsWWnAJGDO"
   },
   "source": [
    "## 4. Nuvem de palavras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMfKNp_QJGDS"
   },
   "outputs": [],
   "source": [
    "#Juntando todos os textos \n",
    "\n",
    "# Textos com StopWords\n",
    "todas_reclamacoes = \" \".join(review for review in reclamacoes.corpo_reclamacao_lower)\n",
    "\n",
    "# Texto sem StopWords\n",
    "todas_reclamacoes_semStopWords = \" \".join(review for review in reclamacoes.corpo_reclamacao_semStopWords)\n",
    "\n",
    "print (\"Temos {} palavras juntando todas as reclamações.\".format(len(todas_reclamacoes_semStopWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2SE4huFJGDV"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# World Cloud\n",
    "# Exemplo: World cloud de todas reclamações sem stopwords\n",
    "\n",
    "# Gerando a wordcloud\n",
    "plt.figure(figsize=(10,5))\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(todas_reclamacoes_semStopWords)\n",
    "\n",
    "# Mostrando nuvem de palavras com o matplotlib \n",
    "plt.title('WordCloud sem StopWords', fontsize=20)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_g6zX5eJGDY"
   },
   "outputs": [],
   "source": [
    "# World Cloud\n",
    "# Exemplo: World cloud de todos os textos\n",
    "\n",
    "# Gerando a wordcloud\n",
    "plt.figure(figsize=(10,5))\n",
    "wordcloud = WordCloud(background_color=\"white\").generate(todas_reclamacoes)\n",
    "\n",
    "#Mostrando nuvem de palavras com o matplotlib \n",
    "plt.title('WordCloud com StopWords', fontsize=20)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4TemHX-JGDb"
   },
   "source": [
    "Reparem na diferença na visualização. \n",
    "\n",
    "Na segunda, o resultado é muito menos util para um tomador de decisão que o primeiro.\n",
    "\n",
    "Por exemplo, \"problema\", \"pedido\", \"gerente\", podem ser palavras a levantar um alerta dentor da empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yiHS8wcJGDb"
   },
   "outputs": [],
   "source": [
    "# Exercicios: World cloud de uma unica empresa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoOlZIcfJGDd"
   },
   "source": [
    "### 4.1 Nuvem de palavras com Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kShseaq3OCGI"
   },
   "outputs": [],
   "source": [
    "# Selecionar a imagem que será utilizada como template\n",
    "# OBS: A imagem precisa estar na mesma pasta que o notebook!\n",
    "\n",
    "# Para executar na sua maquina\n",
    "#py_mask = np.array(Image.open(\"girls.png\")) \n",
    "\n",
    "# Para executar no Google Colab\n",
    "uploaded = files.upload()\n",
    "py_mask = np.array(Image.open(io.BytesIO(uploaded['girls.png'])))\n",
    "\n",
    "# Cria a WordCloud passando a imagem selecionada acima como mascara\n",
    "wc = WordCloud(background_color=\"white\", max_words=10000, mask=py_mask,margin=1)\n",
    "\n",
    "wc.generate(todas_reclamacoes_semStopWords)\n",
    "\n",
    "# Salva a imagem na sua maquina :)\n",
    "wc.to_file(\"girls_wordcloud.png\")\n",
    "\n",
    "plt.figure(figsize=[20,10])\n",
    "\n",
    "image_colors = ImageColorGenerator(py_mask)\n",
    "plt.imshow(wc.recolor(color_func=image_colors), interpolation='bilinear' )\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikVnN_zrJGDf"
   },
   "source": [
    "# BONUS\n",
    "\n",
    "# Um pouco de Deep Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kLqdYqXpJGDf"
   },
   "source": [
    "Vamos agora entrar no mundo do Deep Learning!\n",
    "\n",
    "Par isso vamos utilizar o Spacy, uma poderosa bilioteca de Processamento de Linguagem Natural e é focada em \"entender\" grandes quantidades de texto.\n",
    "\n",
    "Para instalar descomente a celula abaixo:\n",
    "\n",
    "<b>ATENÇÃO:</b> Para instalar o Spacy na sua maquina pessoal é necessario ter o Microsoft Visual C++ 14.0 (visual studio) instalado na maquina. No Colab ele já vem pré-instalado :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0kWJd7fJGDg"
   },
   "outputs": [],
   "source": [
    "# Se já não tiver instalado o spacy...\n",
    "\n",
    "!pip install spacy\n",
    "# !python -m spacy download en\n",
    "!python -m spacy download pt\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07P4SH5FJGDi"
   },
   "source": [
    "## 1. Primeiros passos com o Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eqORdqSJGDj"
   },
   "outputs": [],
   "source": [
    "# Vamos usar o modelo pré-pronto que acabamos de baixar\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm') # Importando o modelo pré treinado de Deep Learning do Spacy em Português!\n",
    "\n",
    "# Passando uma frase para o spacy\n",
    "doc = nlp(u'Eai! Já ta sabendo tudo sobre NLP? A Camila conhece também, vou pedir pra ela me dar umas aulas')\n",
    "# Obs: Repare no unicode na string...você deve usa-lo para que funcione corretamente.\n",
    "\n",
    "# Tambem podemos Tokenizar o texto pelo Sapcy hehe\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCUJtCSjJGDl"
   },
   "source": [
    "## 2. Identificação de Entidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VYkaqb0JGDm"
   },
   "source": [
    "A identificação de Entidade (em inglês Named Entity Recognition - NER) é a identificação de objetos/itens/coisas do mundo real, por exemplo, uma pessoa, um produto, um pais ou estado.\n",
    "\n",
    "Com o Spacy é possivel se treinar seu proprio algoritmo de NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLoKIEjVJGDm"
   },
   "outputs": [],
   "source": [
    "# Entidades\n",
    "\n",
    "doc = nlp(u\"Apesar da Maria morar em São Paulo, ela me disse que seu sonho era morar em Nova York\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print('Texto: {}'.format(ent.text))\n",
    "    print('Inicio: {}'.format(ent.start_char))\n",
    "    print('Fim: {}'.format(ent.end_char))\n",
    "    print('Entidade: {}'.format(ent.label_))\n",
    "    print('----'*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yu5Wni8mJGDq"
   },
   "source": [
    "Lista com os tipos de Entidade suportados/Identificados pelo Spacy: https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoJbF5enJGDr"
   },
   "outputs": [],
   "source": [
    "# Visualizando de uma forma mais bonita!\n",
    "\n",
    "from spacy import displacy\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "html = displacy.render(doc, style=\"ent\")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkhnBLK2JGDt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sua vez!\n",
    "\n",
    "# Exercicios: Aplique NER nas reclamações de uma empresa que você queira, quais entidades foram as mais retornadas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b9wZj15JGDx"
   },
   "source": [
    "## 3. Part-of-speech tagging - POS Tagging\n",
    "\n",
    "### Análise de classes gramaticais "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMwSrmrFJGDx"
   },
   "source": [
    "Depois de tokenizar o texto é possivel identificar a classe gramatical de cada palavra/token (por exemplo, substantivo ou verbo)\n",
    "\n",
    "Essa tecnica é bastante usada na geração automatica de legendas ou até mesmo na tradução automatica, pois com ela podemos entender o contexto da frase e inferir qual a proxima palavra é mais propensa a ser a correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4y33EQKTJGDy"
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'Apesar da Maria morar em São Paulo, ela me disse que seu sonho era morar em Nova York')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-bRZqjVJGD1"
   },
   "outputs": [],
   "source": [
    "html = displacy.render(doc, style=\"dep\")\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpmvbFRSOCGj"
   },
   "source": [
    "# Fim :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2-Intro_NLP.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
